{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnAHaZLZtZCYFoeI8YhorC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shehab-Mechanical/codes/blob/main/HCT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWTbik6eSIwE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Load Data\n",
        "# Update these file paths as necessary based on your local setup.\n",
        "train_file = \"path_to_train.csv\"  # Replace with the path to Train.csv\n",
        "test_file = \"path_to_test.csv\"  # Replace with the path to Test.csv\n",
        "data_dict_file = \"path_to_data_dictionary.csv\"  # Replace with Data Dictionary.csv\n",
        "sample_submission_file = \"path_to_sample_submission.csv\"  # Replace with Sample Submission.csv\n",
        "\n",
        "# Load the data\n",
        "data_dict = pd.read_csv(data_dict_file)\n",
        "train_data = pd.read_csv(train_file)\n",
        "test_data = pd.read_csv(test_file)\n",
        "sample_submission = pd.read_csv(sample_submission_file)\n",
        "\n",
        "# Step 2: Data Exploration\n",
        "print(\"Data Dictionary Preview:\\n\", data_dict.head())\n",
        "print(\"\\nTrain Data Preview:\\n\", train_data.head())\n",
        "print(\"\\nTest Data Preview:\\n\", test_data.head())\n",
        "print(\"\\nSample Submission Preview:\\n\", sample_submission.head())\n",
        "\n",
        "print(\"\\nTrain Data Info:\\n\")\n",
        "train_data.info()\n",
        "\n",
        "print(\"\\nTest Data Info:\\n\")\n",
        "test_data.info()\n",
        "\n",
        "# Step 3: Handle Missing Values and Preprocessing\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=[\"ID\", \"TargetColumn\"])  # Replace \"TargetColumn\" with the actual target column name.\n",
        "y = train_data[\"TargetColumn\"]\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Preprocessing pipelines\n",
        "num_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", LabelEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformer, num_features),\n",
        "        (\"cat\", cat_transformer, cat_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 4: Split Data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Build the Model Pipeline\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Step 6: Train the Model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "val_predictions = model.predict(X_val)\n",
        "mse = mean_squared_error(y_val, val_predictions)\n",
        "print(\"Validation Mean Squared Error:\", mse)\n",
        "\n",
        "# Step 8: Predict on Test Data\n",
        "X_test = test_data.drop(columns=[\"ID\"])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Step 9: Save Submission\n",
        "submission = sample_submission.copy()\n",
        "submission[\"prediction\"] = test_predictions\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission file saved as submission.csv\")\n",
        "\n",
        "# Step 10: Visualizations (Optional)\n",
        "sns.histplot(y, kde=True)\n",
        "plt.title(\"Target Variable Distribution\")\n",
        "plt.show()\n"
      ]
    }
  ]
}